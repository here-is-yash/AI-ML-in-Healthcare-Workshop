{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Problem_3_by.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms as T\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import albumentations as albu\n",
        "\n",
        "import time\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-05T17:06:17.027514Z",
          "iopub.execute_input": "2022-04-05T17:06:17.028103Z",
          "iopub.status.idle": "2022-04-05T17:06:20.930112Z",
          "shell.execute_reply.started": "2022-04-05T17:06:17.028000Z",
          "shell.execute_reply": "2022-04-05T17:06:20.929233Z"
        },
        "trusted": true,
        "id": "TCsnOy_clLeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "l2R2wuW5lV6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install -U git+https://github.com/albu/albumentations --no-cache-dir\n",
        "\n",
        "#!pip uninstall opencv-python-headless==4.5.5.62 \n",
        "!#pip install opencv-python-headless==4.5.2.52"
      ],
      "metadata": {
        "id": "lVNKVObqcx82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "nwInosANlLee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Train_IMAGE_PATH = '/content/drive/MyDrive/workshop_april2022_BraTS/Images/train/images/'\n",
        "Train_MASK_PATH = '/content/drive/MyDrive/workshop_april2022_BraTS/Images/train/mask/'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-05T17:06:20.931673Z",
          "iopub.execute_input": "2022-04-05T17:06:20.931937Z",
          "iopub.status.idle": "2022-04-05T17:06:20.935514Z",
          "shell.execute_reply.started": "2022-04-05T17:06:20.931902Z",
          "shell.execute_reply": "2022-04-05T17:06:20.934795Z"
        },
        "trusted": true,
        "id": "2FJsFu1WlLej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = 3\n",
        "\n",
        "def create_df(IMAGE_PATH, MASK_PATH):\n",
        "    name = []\n",
        "    for dirname, _, filenames in os.walk(MASK_PATH):\n",
        "        for filename in filenames:\n",
        "            if(os.path.exists(IMAGE_PATH + filename.split('.')[0][:-3]+\"flair.png\")):\n",
        "              name.append(filename.split('.')[0])\n",
        "    \n",
        "    return pd.DataFrame({'id': name}, index = np.arange(0, len(name)))\n",
        "\n",
        "df = create_df(Train_IMAGE_PATH, Train_MASK_PATH)\n",
        "print('Total Images: ', len(df))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-05T17:06:21.501199Z",
          "iopub.execute_input": "2022-04-05T17:06:21.501832Z",
          "iopub.status.idle": "2022-04-05T17:06:27.818180Z",
          "shell.execute_reply.started": "2022-04-05T17:06:21.501795Z",
          "shell.execute_reply": "2022-04-05T17:06:27.817473Z"
        },
        "trusted": true,
        "id": "R1bCAMIClLel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Val_IMAGE_PATH = \"/content/drive/MyDrive/workshop_april2022_BraTS/Images/val/images/\"\n",
        "Val_MASK_PATH = \"/content/drive/MyDrive//workshop_april2022_BraTS/Images/val/mask/\"\n",
        "Test_IMAGE_PATH = \"/content/drive/MyDrive/workshop_april2022_BraTS/Images/test/images/\"\n",
        "Test_MASK_PATH = \"/content/drive/MyDrive/workshop_april2022_BraTS/Images/test/mask/\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-05T17:06:27.819514Z",
          "iopub.execute_input": "2022-04-05T17:06:27.819854Z",
          "iopub.status.idle": "2022-04-05T17:06:27.823671Z",
          "shell.execute_reply.started": "2022-04-05T17:06:27.819826Z",
          "shell.execute_reply": "2022-04-05T17:06:27.823093Z"
        },
        "trusted": true,
        "id": "USk717vnlLeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_val = create_df(Val_IMAGE_PATH, Val_MASK_PATH)\n",
        "print('Total Val Images: ', len(df_val))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-05T17:06:27.826301Z",
          "iopub.execute_input": "2022-04-05T17:06:27.826635Z",
          "iopub.status.idle": "2022-04-05T17:06:27.935551Z",
          "shell.execute_reply.started": "2022-04-05T17:06:27.826610Z",
          "shell.execute_reply": "2022-04-05T17:06:27.934602Z"
        },
        "trusted": true,
        "id": "Ix2ASqdFlLep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = create_df(Test_IMAGE_PATH, Test_MASK_PATH)\n",
        "print('Total Test Images: ', len(df_test))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-05T17:06:27.937188Z",
          "iopub.execute_input": "2022-04-05T17:06:27.937873Z",
          "iopub.status.idle": "2022-04-05T17:06:27.961457Z",
          "shell.execute_reply.started": "2022-04-05T17:06:27.937840Z",
          "shell.execute_reply": "2022-04-05T17:06:27.960600Z"
        },
        "trusted": true,
        "id": "OWnaYcjAlLer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open(Train_IMAGE_PATH + df['id'][100][:-3] + 'flair.png')\n",
        "mask = Image.open(Train_MASK_PATH + df['id'][100] + '.png')\n",
        "print('Image Size', np.asarray(img).shape)\n",
        "print('Mask Size', np.asarray(mask).shape)\n",
        "\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.imshow(mask, alpha=0.6)\n",
        "plt.title('Picture with Mask Appplied')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-05T17:06:27.962435Z",
          "iopub.execute_input": "2022-04-05T17:06:27.962628Z",
          "iopub.status.idle": "2022-04-05T17:06:28.332186Z",
          "shell.execute_reply.started": "2022-04-05T17:06:27.962605Z",
          "shell.execute_reply": "2022-04-05T17:06:28.331325Z"
        },
        "trusted": true,
        "id": "esJnVZLrlLes",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_map = [[0., 0., 0.], [0. , 255., 0.], [255., 0., 0.]]\n",
        "\n",
        "# 0 -> background,  1. Tumor, 2. Edema"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-05T17:06:28.333443Z",
          "iopub.execute_input": "2022-04-05T17:06:28.333880Z",
          "iopub.status.idle": "2022-04-05T17:06:28.338823Z",
          "shell.execute_reply.started": "2022-04-05T17:06:28.333841Z",
          "shell.execute_reply": "2022-04-05T17:06:28.338059Z"
        },
        "trusted": true,
        "id": "dtDC1ngHlLeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''This method will convert mask labels(to be trained) from RGB to a 2D image which holds class labels of the pixels.'''\n",
        "def form_2D_label(mask,class_map):\n",
        "    #mask = mask.astype(\"uint8\")\n",
        "    label = np.zeros(mask.shape[:2],dtype= np.uint8)\n",
        "    \n",
        "    for i, rgb in enumerate(class_map):\n",
        "        label[(mask == rgb).all(axis=2)] = i\n",
        "    \n",
        "    return label"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-05T17:06:28.340220Z",
          "iopub.execute_input": "2022-04-05T17:06:28.340686Z",
          "iopub.status.idle": "2022-04-05T17:06:28.351314Z",
          "shell.execute_reply.started": "2022-04-05T17:06:28.340648Z",
          "shell.execute_reply": "2022-04-05T17:06:28.350184Z"
        },
        "trusted": true,
        "id": "T6_E7F8BlLew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#try finding out the pixels of each colour\n"
      ],
      "metadata": {
        "id": "_2lcXSNNhCga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class_count = np.asarray([560201119,  95301323,  29131557,  25300594,  20709887])\n",
        "# tot = np.sum(class_count)\n",
        "\n",
        "# class_weights = (tot - class_count)/tot\n",
        "# print(class_weights)\n",
        "# weights = torch.tensor(list(class_weights)).to(device, dtype = torch.float)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-05T17:06:28.352793Z",
          "iopub.execute_input": "2022-04-05T17:06:28.353168Z",
          "iopub.status.idle": "2022-04-05T17:06:28.388625Z",
          "shell.execute_reply.started": "2022-04-05T17:06:28.353127Z",
          "shell.execute_reply": "2022-04-05T17:06:28.387970Z"
        },
        "trusted": true,
        "id": "yphY39GmlLex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = [0.233278, 0.960128, 0.965372]\n",
        "class_weights = torch.tensor(list(class_weights)).to(device, dtype = torch.float)"
      ],
      "metadata": {
        "id": "kRIpIy2qZtXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CytoDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, img_path, mask_path, X , transform=None):\n",
        "        self.img_path = img_path\n",
        "        self.mask_path = mask_path\n",
        "        self.X = X\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.img_path + self.X[idx][:-3] + 'flair.png')\n",
        "        #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        mask = Image.open(self.mask_path + self.X[idx] + '.png')\n",
        "        #img = (img - img.min())/(img.max() - img.min())\n",
        "        img= np.asarray(img)\n",
        "        mask= np.asarray(mask)\n",
        "\n",
        "        if(self.transform != None):\n",
        "            augmented = self.transform(image=img, mask=mask)\n",
        "            img = augmented[\"image\"]\n",
        "            mask = augmented[\"mask\"]\n",
        "    \n",
        "        t = T.Compose([T.ToTensor()])\n",
        "        img = t(img)\n",
        "        mask = form_2D_label(mask, class_map)\n",
        "        mask = torch.from_numpy(mask).long()\n",
        "            \n",
        "        return img, mask"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-05T17:06:28.389743Z",
          "iopub.execute_input": "2022-04-05T17:06:28.390073Z",
          "iopub.status.idle": "2022-04-05T17:06:28.398037Z",
          "shell.execute_reply.started": "2022-04-05T17:06:28.390045Z",
          "shell.execute_reply": "2022-04-05T17:06:28.397313Z"
        },
        "trusted": true,
        "id": "QPcvJO3SlLey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transform = albu.Compose([\n",
        "#     albu.HorizontalFlip(p=0.5),\n",
        "#     albu.VerticalFlip(p=0.5),\n",
        "#     albu.CropAndPad (percent = -0.2, keep_size=True, interpolation=cv2.INTER_NEAREST, p=0.5),\n",
        "#     albu.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit= 15, interpolation= cv2.INTER_NEAREST,\n",
        "#                                           border_mode= cv2.BORDER_REPLICATE, p=0.5)\n",
        "# ])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-05T17:06:28.400142Z",
          "iopub.execute_input": "2022-04-05T17:06:28.400894Z",
          "iopub.status.idle": "2022-04-05T17:06:28.410541Z",
          "shell.execute_reply.started": "2022-04-05T17:06:28.400860Z",
          "shell.execute_reply": "2022-04-05T17:06:28.409767Z"
        },
        "trusted": true,
        "id": "TaPsplqBlLe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = CytoDataset(Train_IMAGE_PATH, Train_MASK_PATH, df['id'].values)\n",
        "val_set = CytoDataset(Val_IMAGE_PATH, Val_MASK_PATH, df_val['id'].values)\n",
        "\n",
        "#dataloader\n",
        "batch_size= 4\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True)  "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-05T17:06:28.411511Z",
          "iopub.execute_input": "2022-04-05T17:06:28.411702Z",
          "iopub.status.idle": "2022-04-05T17:06:28.424572Z",
          "shell.execute_reply.started": "2022-04-05T17:06:28.411679Z",
          "shell.execute_reply": "2022-04-05T17:06:28.423911Z"
        },
        "trusted": true,
        "id": "dmPQPJpLlLe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5IZwQLtRhn14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# for i, data in enumerate(train_loader):\n",
        "#   # print(type(data))\n",
        "#   img,mask = data\n",
        "#   # print(img.shape , mask.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "OBXiPrZkhYcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, mask = train_set.__getitem__(0)"
      ],
      "metadata": {
        "id": "JO4t2R18awIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(img.shape, mask.shape)"
      ],
      "metadata": {
        "id": "m7rud7f9a60Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print( train_set.__len__())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-05T17:06:29.464414Z",
          "iopub.execute_input": "2022-04-05T17:06:29.465285Z",
          "iopub.status.idle": "2022-04-05T17:06:29.470755Z",
          "shell.execute_reply.started": "2022-04-05T17:06:29.465225Z",
          "shell.execute_reply": "2022-04-05T17:06:29.469811Z"
        },
        "trusted": true,
        "id": "o7eRI5FvlLe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# ---------------------------------- Unet model --------------------------------------\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscaling then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        # input is CHW\n",
        "        diffY = torch.tensor([x2.size()[2] - x1.size()[2]])\n",
        "        diffX = torch.tensor([x2.size()[3] - x1.size()[3]])\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        self.down4 = Down(512, 512)\n",
        "        self.up1 = Up(1024, 256, bilinear)\n",
        "        self.up2 = Up(512, 128, bilinear)\n",
        "        self.up3 = Up(256, 64, bilinear)\n",
        "        self.up4 = Up(128, 64, bilinear)\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-05T17:06:30.134357Z",
          "iopub.execute_input": "2022-04-05T17:06:30.134941Z",
          "iopub.status.idle": "2022-04-05T17:06:30.152947Z",
          "shell.execute_reply.started": "2022-04-05T17:06:30.134904Z",
          "shell.execute_reply": "2022-04-05T17:06:30.151784Z"
        },
        "trusted": true,
        "id": "2eLMhVf8lLe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from packaging import version\n",
        "\n",
        "class CrossEntropy2d(nn.Module):\n",
        "\n",
        "    def __init__(self, size_average=True, ignore_label=255):\n",
        "        super(CrossEntropy2d, self).__init__()\n",
        "        self.size_average = size_average\n",
        "        self.ignore_label = ignore_label\n",
        "\n",
        "    def forward(self, predict, target, weight=None):\n",
        "        \"\"\"\n",
        "            Args:\n",
        "                predict:(n, c, h, w)\n",
        "                target:(n, h, w)\n",
        "                weight (Tensor, optional): a manual rescaling weight given to each class.\n",
        "                                           If given, has to be a Tensor of size \"nclasses\"\n",
        "        \"\"\"\n",
        "        assert not target.requires_grad\n",
        "        assert predict.dim() == 4\n",
        "        assert target.dim() == 3\n",
        "        assert predict.size(0) == target.size(0), \"{0} vs {1} \".format(predict.size(0), target.size(0))\n",
        "        assert predict.size(2) == target.size(1), \"{0} vs {1} \".format(predict.size(2), target.size(1))\n",
        "        assert predict.size(3) == target.size(2), \"{0} vs {1} \".format(predict.size(3), target.size(3))\n",
        "        n, c, h, w = predict.size()\n",
        "        target_mask = (target >= 0) * (target != self.ignore_label)\n",
        "        target = target[target_mask]\n",
        "        if not target.data.dim():\n",
        "            return Variable(torch.zeros(1))\n",
        "        predict = predict.transpose(1, 2).transpose(2, 3).contiguous()\n",
        "        predict = predict[target_mask.view(n, h, w, 1).repeat(1, 1, 1, c)].view(-1, c)\n",
        "        loss = F.cross_entropy(predict, target, weight=weight, size_average=self.size_average)\n",
        "        return loss\n",
        "\n",
        "\n",
        "# class BCEWithLogitsLoss2d(nn.Module):\n",
        "\n",
        "#     def __init__(self, size_average=True, ignore_label=255):\n",
        "#         super(BCEWithLogitsLoss2d, self).__init__()\n",
        "#         self.size_average = size_average\n",
        "#         self.ignore_label = ignore_label\n",
        "\n",
        "#     def forward(self, predict, target, weight=None):\n",
        "#         \"\"\"\n",
        "#             Args:\n",
        "#                 predict:(n, 1, h, w)\n",
        "#                 target:(n, 1, h, w)\n",
        "#                 weight (Tensor, optional): a manual rescaling weight given to each class.\n",
        "#                                            If given, has to be a Tensor of size \"nclasses\"\n",
        "#         \"\"\"\n",
        "#         assert not target.requires_grad\n",
        "#         assert predict.dim() == 4\n",
        "#         assert target.dim() == 4\n",
        "#         assert predict.size(0) == target.size(0), \"{0} vs {1} \".format(predict.size(0), target.size(0))\n",
        "#         assert predict.size(2) == target.size(2), \"{0} vs {1} \".format(predict.size(2), target.size(2))\n",
        "#         assert predict.size(3) == target.size(3), \"{0} vs {1} \".format(predict.size(3), target.size(3))\n",
        "#         n, c, h, w = predict.size()\n",
        "#         target_mask = (target >= 0) * (target != self.ignore_label)\n",
        "#         target = target[target_mask]\n",
        "#         if not target.data.dim():\n",
        "#             return Variable(torch.zeros(1))\n",
        "#         predict = predict[target_mask]\n",
        "#         loss = F.binary_cross_entropy_with_logits(predict, target, weight=weight, size_average=self.size_average)\n",
        "#         return loss"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-05T17:06:31.119590Z",
          "iopub.execute_input": "2022-04-05T17:06:31.119880Z",
          "iopub.status.idle": "2022-04-05T17:06:31.135587Z",
          "shell.execute_reply.started": "2022-04-05T17:06:31.119850Z",
          "shell.execute_reply": "2022-04-05T17:06:31.134609Z"
        },
        "trusted": true,
        "id": "HZB41mV5lLe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = {'IMG_MEAN' : np.array((104.00698793,116.66876762,122.67891434), dtype=np.float32),  \n",
        "        'MODEL' : 'U_net' , 'BATCH_SIZE' : 4,\n",
        "'ITER_SIZE' : 1,  'NUM_WORKERS' : 4, \n",
        "'IGNORE_LABEL' : 255 , 'INPUT_SIZE' : '384,384' , 'LEARNING_RATE' : 2.5e-4 , 'MOMENTUM' : 0.9,  'NUM_CLASSES' : 3, \n",
        "'NUM_STEPS' : 20000, \n",
        "'POWER' : 0.9,\n",
        "'RANDOM_SEED' : 1234,\n",
        "'SAVE_NUM_IMAGES' : 2,\n",
        "'SAVE_PRED_EVERY' : 5000,\n",
        "'SNAPSHOT_DIR' : './snapshots/',\n",
        "'WEIGHT_DECAY' : 0.0005,\n",
        "\n",
        "'LEARNING_RATE_D' : 1e-4,\n",
        "'LAMBDA_ADV_PRED' : 0.1,\n",
        "'PARTIAL_DATA' : None, #0.5,\n",
        "\n",
        "'SEMI_START' : 5000,\n",
        "'LAMBDA_SEMI' : 0.1,\n",
        "'MASK_T' : 0.2,\n",
        "\n",
        "'LAMBDA_SEMI_ADV':0.001,\n",
        "'SEMI_START_ADV' : 0,\n",
        "'D_REMAIN' : False, 'GPU':True,\n",
        "       'RESTORE_FROM' : 'http://vllab1.ucmerced.edu/~whung/adv-semi-seg/resnet101COCO-41f33a49.pth'}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-05T17:06:33.911649Z",
          "iopub.execute_input": "2022-04-05T17:06:33.912422Z",
          "iopub.status.idle": "2022-04-05T17:06:33.918762Z",
          "shell.execute_reply.started": "2022-04-05T17:06:33.912381Z",
          "shell.execute_reply": "2022-04-05T17:06:33.918125Z"
        },
        "trusted": true,
        "id": "ufJdO5iilLe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import copy_reg\n",
        "except:\n",
        "    import copyreg as copy_reg"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-05T17:06:34.579485Z",
          "iopub.execute_input": "2022-04-05T17:06:34.580253Z",
          "iopub.status.idle": "2022-04-05T17:06:34.583947Z",
          "shell.execute_reply.started": "2022-04-05T17:06:34.580212Z",
          "shell.execute_reply": "2022-04-05T17:06:34.583312Z"
        },
        "trusted": true,
        "id": "YTMqt5FQlLe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pixel_accuracy(output, mask):\n",
        "    with torch.no_grad():\n",
        "        output = torch.argmax(F.softmax(output, dim=1), dim=1)\n",
        "        correct = torch.eq(output, mask).int()\n",
        "        accuracy = float(correct.sum()) / float(correct.numel())\n",
        "    return accuracy\n",
        "\n",
        "def mIoU(pred_mask, mask, smooth=1e-10, n_classes=5):\n",
        "    with torch.no_grad():\n",
        "        pred_mask = F.softmax(pred_mask, dim=1)\n",
        "        pred_mask = torch.argmax(pred_mask, dim=1)\n",
        "        pred_mask = pred_mask.contiguous().view(-1)\n",
        "        mask = mask.contiguous().view(-1)\n",
        "\n",
        "        iou_per_class = []\n",
        "        for clas in range(0, n_classes): #loop per pixel class\n",
        "            true_class = pred_mask == clas\n",
        "            true_label = mask == clas\n",
        "\n",
        "            if true_label.long().sum().item() == 0: #no exist label in this loop\n",
        "                iou_per_class.append(np.nan)\n",
        "            else:\n",
        "                intersect = torch.logical_and(true_class, true_label).sum().float().item()\n",
        "                union = torch.logical_or(true_class, true_label).sum().float().item()\n",
        "\n",
        "                iou = (intersect + smooth) / (union +smooth)\n",
        "                iou_per_class.append(iou)\n",
        "        return np.nanmean(iou_per_class)\n",
        "    \n",
        "def map_thiss(y_pred,class_map):\n",
        "    y_pred_rgb = np.zeros((y_pred.shape[0],y_pred.shape[1],y_pred.shape[2],3))\n",
        "    for i in range(y_pred.shape[0]):\n",
        "        image = np.zeros((y_pred.shape[1],y_pred.shape[2],3))\n",
        "        for j in range(y_pred.shape[1]):\n",
        "            for k in range(y_pred.shape[2]):\n",
        "                image[j,k,:] = class_map[int(y_pred[i][j][k])]\n",
        "        y_pred_rgb[i] = image\n",
        "    return y_pred_rgb\n",
        "\n",
        "def plot_result(img , title):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.title(title)\n",
        "    for i in range(4):\n",
        "        #print(pred[i].shape)\n",
        "        plt.subplot(2, 4, i+1)\n",
        "        plt.imshow(img[i])\n",
        "    plt.show()\n",
        "    \n",
        "def export_model(model, optimizer=None, name=None, step=None):\n",
        "\n",
        "        # set output filename\n",
        "        if name is not None:\n",
        "            out_file = name\n",
        "        else:\n",
        "            out_file = \"checkpoint\"\n",
        "        if step is not None:\n",
        "            out_file += \"_step_\" + str(step)\n",
        "            \n",
        "        out_file = os.path.join(\"./\", out_file + \".pth\")\n",
        "\n",
        "        # save model\n",
        "        data = {\"model_state_dict\": model.state_dict()}\n",
        "        if step is not None:\n",
        "            data[\"step\"] = step\n",
        "        if optimizer is not None:\n",
        "            data[\"optimizer_state_dict\"] = optimizer.state_dict()\n",
        "        torch.save(data, out_file)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-05T17:06:35.322122Z",
          "iopub.execute_input": "2022-04-05T17:06:35.322727Z",
          "iopub.status.idle": "2022-04-05T17:06:35.337885Z",
          "shell.execute_reply.started": "2022-04-05T17:06:35.322679Z",
          "shell.execute_reply": "2022-04-05T17:06:35.337290Z"
        },
        "trusted": true,
        "id": "XNKtXQm1lLe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "def loss_calc(pred, label, gpu):\n",
        "    \"\"\"\n",
        "    This function returns cross entropy loss for semantic segmentation\n",
        "    \"\"\"\n",
        "    # out shape batch_size x channels x h x w -> batch_size x channels x h x w\n",
        "    # label shape h x w x 1 x batch_size  -> batch_size x 1 x h x w\n",
        "    label = Variable(label.long()).cuda(device)\n",
        "    criterion = CrossEntropy2d().cuda(device)\n",
        "    #criterion = CrossEntropy2d()\n",
        "\n",
        "    return criterion(pred, label)\n",
        "\n",
        "\n",
        "def lr_poly(base_lr, iter, max_iter, power):\n",
        "    return base_lr*((1-float(iter)/max_iter)**(power))\n",
        "\n",
        "\n",
        "# def adjust_learning_rate(optimizer, i_iter):\n",
        "#     lr = lr_poly(args[\"LEARNING_RATE\"], i_iter, args[\"NUM_STEPS\"], args[\"POWER\"])\n",
        "#     optimizer.param_groups[0]['lr'] = lr\n",
        "#     if len(optimizer.param_groups) > 1 :\n",
        "#         optimizer.param_groups[1]['lr'] = lr * 10\n",
        "\n",
        "# def adjust_learning_rate_D(optimizer, i_iter):\n",
        "#     lr = lr_poly(args[\"LEARNING_RATE_D\"], i_iter, args[\"NUM_STEPS\"], args[\"POWER\"])\n",
        "#     optimizer.param_groups[0]['lr'] = lr\n",
        "#     if len(optimizer.param_groups) > 1 :\n",
        "#         optimizer.param_groups[1]['lr'] = lr * 10\n",
        "\n",
        "# def one_hot(label):\n",
        "#     label = label.numpy()\n",
        "#     one_hot = np.zeros((label.shape[0], args[\"NUM_CLASSES\"], label.shape[1], label.shape[2]), dtype=label.dtype)\n",
        "#     for i in range(args[\"NUM_CLASSES\"]):\n",
        "#         one_hot[:,i,...] = (label==i)\n",
        "#     #handle ignore labels\n",
        "#     return torch.FloatTensor(one_hot)\n",
        "\n",
        "# def make_D_label(label, ignore_mask):\n",
        "#     ignore_mask = np.expand_dims(ignore_mask, axis=1)\n",
        "#     D_label = np.ones(ignore_mask.shape)*label\n",
        "#     D_label[ignore_mask] = 255\n",
        "#     D_label = Variable(torch.FloatTensor(D_label)).cuda(device)\n",
        "\n",
        "#     return D_label"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-05T17:10:05.277743Z",
          "iopub.execute_input": "2022-04-05T17:10:05.278422Z",
          "iopub.status.idle": "2022-04-05T17:10:05.290543Z",
          "shell.execute_reply.started": "2022-04-05T17:10:05.278375Z",
          "shell.execute_reply": "2022-04-05T17:10:05.289902Z"
        },
        "trusted": true,
        "id": "rz8eSe1ClLe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "def fit(epochs, model, train_loader, val_loader, criterion, optimizer, scheduler, patch=False):\n",
        "    torch.cuda.empty_cache()\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    val_iou = []; val_acc = []\n",
        "    train_iou = []; train_acc = []\n",
        "    lrs = []\n",
        "    min_loss = np.inf\n",
        "    decrease = 1 ; not_improve=0\n",
        "\n",
        "    model.to(device)\n",
        "    fit_time = time.time()\n",
        "    for e in range(epochs):\n",
        "        since = time.time()\n",
        "        running_loss = 0\n",
        "        iou_score = 0\n",
        "        accuracy = 0\n",
        "        #training loop\n",
        "        model.train()\n",
        "        for i, data in enumerate(tqdm(train_loader)):\n",
        "            #training phase\n",
        "            image_tiles, mask_tiles = data\n",
        "            #image = image_tiles\n",
        "            #mask = mask_tiles\n",
        "            image = image_tiles.to(device, dtype = torch.float); mask = mask_tiles.to(device, dtype= torch.float);\n",
        "            #forward\n",
        "            output = model(image)\n",
        "            loss = loss_calc(output, mask, device)\n",
        "            #evaluation metrics\n",
        "            \n",
        "            iou_score += mIoU(output, mask)\n",
        "            accuracy += pixel_accuracy(output, mask)\n",
        "            #backward\n",
        "            loss.backward()\n",
        "            optimizer.step() #update weight          \n",
        "            optimizer.zero_grad() #reset gradient\n",
        "            \n",
        "            #step the learning rate\n",
        "            lrs.append(get_lr(optimizer))\n",
        "            scheduler.step() \n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            \n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        test_accuracy = 0\n",
        "        val_iou_score = 0\n",
        "        #validation loop\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(tqdm(val_loader)):\n",
        "                #reshape to 9 patches from single image, delete batch size\n",
        "                image_tiles, mask_tiles = data\n",
        "                #image = image_tiles\n",
        "                #mask = mask_tiles\n",
        "                image = image_tiles.to(device, dtype = torch.float); mask = mask_tiles.to(device, dtype = torch.float);\n",
        "                output = model(image)\n",
        "                #evaluation metrics\n",
        "                # print(loss)\n",
        "                if(i==1):\n",
        "                    output_soft = F.softmax(output, dim=1)\n",
        "                    output_num = output_soft.cpu().detach().numpy()\n",
        "                    pred_mask = np.argmax(output_num, axis = 1)\n",
        "        \n",
        "                    y_pred_rgb = map_thiss(pred_mask,class_map)\n",
        "                    y_test_rgb = map_thiss(mask,class_map)\n",
        "                    plot_result(y_test_rgb,\"Original Masks\")\n",
        "                    plot_result(y_pred_rgb,\"Predicted Masks\")\n",
        "                val_iou_score +=  mIoU(output, mask)\n",
        "                test_accuracy += pixel_accuracy(output, mask)\n",
        "                #loss\n",
        "                loss = loss_calc(output, mask, device)                                  \n",
        "                test_loss += loss.item()\n",
        "            \n",
        "        #calculatio mean for each batch\n",
        "        train_losses.append(running_loss/len(train_loader))\n",
        "        test_losses.append(test_loss/len(val_loader))\n",
        "\n",
        "\n",
        "        if min_loss > (test_loss/len(val_loader)):\n",
        "            print('Loss Decreasing.. {:.3f} >> {:.3f} '.format(min_loss, (test_loss/len(val_loader))))\n",
        "            min_loss = (test_loss/len(val_loader))\n",
        "            decrease += 1\n",
        "            #if decrease % 5 == 0:\n",
        "            print('saving model...')\n",
        "            export_model(model, optimizer=optimizer, name=\"final\", step = e)\n",
        "            #torch.save(model, 'Unet-Mobilenet_v2_val_loss-{:.3f}.pt'.format(test_loss/len(val_loader)))\n",
        "\n",
        "\n",
        "        if (test_loss/len(val_loader)) > min_loss:\n",
        "            not_improve += 1\n",
        "            min_loss = (test_loss/len(val_loader))\n",
        "            print(f'Loss Not Decrease for {not_improve} time')\n",
        "            #if not_improve == 7:\n",
        "                #print('Loss not decrease for 7 times, Stop Training')\n",
        "                #break\n",
        "\n",
        "        #iou\n",
        "        val_iou.append(val_iou_score/len(val_loader))\n",
        "        train_iou.append(iou_score/len(train_loader))\n",
        "        train_acc.append(accuracy/len(train_loader))\n",
        "        val_acc.append(test_accuracy/ len(val_loader))\n",
        "        print(\"Epoch:{}/{}..\".format(e+1, epochs),\n",
        "              \"Train Loss: {:.3f}..\".format(running_loss/len(train_loader)),\n",
        "              \"Val Loss: {:.3f}..\".format(test_loss/len(val_loader)),\n",
        "              \"Train mIoU:{:.3f}..\".format(iou_score/len(train_loader)),\n",
        "              \"Val mIoU: {:.3f}..\".format(val_iou_score/len(val_loader)),\n",
        "              \"Train Acc:{:.3f}..\".format(accuracy/len(train_loader)),\n",
        "              \"Val Acc:{:.3f}..\".format(test_accuracy/len(val_loader)),\n",
        "              \"Time: {:.2f}m\".format((time.time()-since)/60))\n",
        "        \n",
        "    history = {'train_loss' : train_losses, 'val_loss': test_losses,\n",
        "               'train_miou' :train_iou, 'val_miou':val_iou,\n",
        "               'train_acc' :train_acc, 'val_acc':val_acc,\n",
        "               'lrs': lrs}\n",
        "    print('Total time: {:.2f} m' .format((time.time()- fit_time)/60))\n",
        "    return history"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-05T17:11:40.658408Z",
          "iopub.execute_input": "2022-04-05T17:11:40.658722Z",
          "iopub.status.idle": "2022-04-05T17:11:40.929927Z",
          "shell.execute_reply.started": "2022-04-05T17:11:40.658692Z",
          "shell.execute_reply": "2022-04-05T17:11:40.928855Z"
        },
        "trusted": true,
        "id": "VKYOWwuolLe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CUDA_LAUNCH_BLOCKING = 1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-05T17:11:41.444619Z",
          "iopub.execute_input": "2022-04-05T17:11:41.445307Z",
          "iopub.status.idle": "2022-04-05T17:11:41.449110Z",
          "shell.execute_reply.started": "2022-04-05T17:11:41.445237Z",
          "shell.execute_reply": "2022-04-05T17:11:41.448303Z"
        },
        "trusted": true,
        "id": "RfZNyswjlLe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_lr = 1e-3\n",
        "epoch = 25\n",
        "weight_decay = 1e-4\n",
        "\n",
        "#model = ResUnetPlusPlus(3).cuda()\n",
        "model = UNet(n_channels=4, n_classes=3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=max_lr, weight_decay=weight_decay)\n",
        "sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epoch,\n",
        "                                            steps_per_epoch=len(train_loader))\n",
        "\n",
        "history = fit(epoch, model, train_loader, val_loader, criterion, optimizer, sched)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-05T17:11:41.971816Z",
          "iopub.execute_input": "2022-04-05T17:11:41.972093Z",
          "iopub.status.idle": "2022-04-05T17:11:42.488051Z",
          "shell.execute_reply.started": "2022-04-05T17:11:41.972060Z",
          "shell.execute_reply": "2022-04-05T17:11:42.486792Z"
        },
        "trusted": true,
        "id": "tPP8voRxlLfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss(history):\n",
        "    plt.plot(history['val_loss'], label='val', marker='o')\n",
        "    plt.plot( history['train_loss'], label='train', marker='o')\n",
        "    plt.title('Loss per epoch'); plt.ylabel('loss');\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(), plt.grid()\n",
        "    plt.show()\n",
        "    \n",
        "def plot_score(history):\n",
        "    plt.plot(history['train_miou'], label='train_mIoU', marker='*')\n",
        "    plt.plot(history['val_miou'], label='val_mIoU',  marker='*')\n",
        "    plt.title('Score per epoch'); plt.ylabel('mean IoU')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(), plt.grid()\n",
        "    plt.show()\n",
        "    \n",
        "def plot_acc(history):\n",
        "    plt.plot(history['train_acc'], label='train_accuracy', marker='*')\n",
        "    plt.plot(history['val_acc'], label='val_accuracy',  marker='*')\n",
        "    plt.title('Accuracy per epoch'); plt.ylabel('Accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(), plt.grid()\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-08T05:47:32.989705Z",
          "iopub.execute_input": "2021-12-08T05:47:32.990033Z",
          "iopub.status.idle": "2021-12-08T05:47:33.000663Z",
          "shell.execute_reply.started": "2021-12-08T05:47:32.990002Z",
          "shell.execute_reply": "2021-12-08T05:47:32.999742Z"
        },
        "trusted": true,
        "id": "ykAnTuBMlLfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss(history)\n",
        "plot_score(history)\n",
        "plot_acc(history)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-08T05:47:35.0716Z",
          "iopub.execute_input": "2021-12-08T05:47:35.071871Z",
          "iopub.status.idle": "2021-12-08T05:47:35.656713Z",
          "shell.execute_reply.started": "2021-12-08T05:47:35.071843Z",
          "shell.execute_reply": "2021-12-08T05:47:35.656021Z"
        },
        "trusted": true,
        "id": "GyrcIaUzlLfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./history.pickle', 'wb') as handle:\n",
        "    pickle.dump(history, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "04fu6VWJlLfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OLHKNyLHeL47"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}